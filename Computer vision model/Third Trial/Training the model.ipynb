{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba40429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting SVR Model Training for Lane Deviation ---\n",
      "Successfully loaded data from: C:/Users/BCI-Lab/Downloads/teamA_dataset/_out_dataset/lane_line_features_extracted.csv\n",
      "Initial dataset shape: (1291, 14)\n",
      "\n",
      "Dataset shape after dropping rows with NaN deviation score: (923, 14)\n",
      "Features (X) shape: (923, 12), Target (y) shape: (923,)\n",
      "Features being used: ['is_line_detected', 'centroid_x_cropped', 'centroid_y_cropped', 'num_line_segments', 'total_line_pixel_length', 'avg_line_angle_deg', 'std_line_angle_deg', 'min_line_y_cropped', 'max_line_y_cropped', 'fitted_line_slope_deg', 'fitted_line_x_intercept_at_bottom_cropped', 'fitted_line_x_intercept_at_top_cropped']\n",
      "\n",
      "Features scaled using StandardScaler.\n",
      "Training data shape: (738, 12), Test data shape: (185, 12)\n",
      "\n",
      "Training SVR model...\n",
      "SVR model training complete.\n",
      "\n",
      "--- Model Evaluation on Test Set ---\n",
      "Mean Absolute Error (MAE): 0.0217\n",
      "R-squared (R2) Score: 0.9902\n",
      "\n",
      "Note: MAE represents the average absolute difference between predicted and actual values.\n",
      "R-squared indicates the proportion of variance in the target that is predictable from the features.\n",
      "\n",
      "✅ Trained SVR model dumped to: trained_model\\svr_deviation_model.joblib\n",
      "✅ Fitted StandardScaler dumped to: trained_model\\feature_scaler.joblib\n",
      "\n",
      "--- Training Complete ---\n",
      "You can now load these files in a new script to make predictions on new, unseen data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib # For saving/loading models and scalers\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to the CSV file generated by the previous feature extraction script\n",
    "# IMPORTANT: Adjust this path if your CSV is in a different location.\n",
    "CSV_FILE_PATH = \"C:/Users/BCI-Lab/Downloads/teamA_dataset/_out_dataset/lane_line_features_extracted.csv\"\n",
    "\n",
    "# Output paths for the trained model and scaler\n",
    "MODEL_OUTPUT_DIR = \"trained_model\"\n",
    "SVR_MODEL_FILENAME = \"svr_deviation_model.joblib\"\n",
    "SCALER_FILENAME = \"feature_scaler.joblib\"\n",
    "\n",
    "# --- Main Script ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Starting SVR Model Training for Lane Deviation ---\")\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "    model_save_path = os.path.join(MODEL_OUTPUT_DIR, SVR_MODEL_FILENAME)\n",
    "    scaler_save_path = os.path.join(MODEL_OUTPUT_DIR, SCALER_FILENAME)\n",
    "\n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_FILE_PATH)\n",
    "        print(f\"Successfully loaded data from: {CSV_FILE_PATH}\")\n",
    "        print(f\"Initial dataset shape: {df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: CSV file not found at '{CSV_FILE_PATH}'.\")\n",
    "        print(\"Please ensure the feature extraction script has been run and the path is correct.\")\n",
    "        exit()\n",
    "\n",
    "    # 2. Handle Missing Values and Define Features/Target\n",
    "    # The 'deviation_score' is NaN when no line is detected.\n",
    "    # For training, we should only use instances where a line was actually detected.\n",
    "    df_cleaned = df.dropna(subset=['deviation_score']).copy() # Drop rows where target is NaN\n",
    "\n",
    "    # Ensure other features also have appropriate values (e.g., 0 or -1 where no line was detected)\n",
    "    # The feature extraction script already assigns these default values, so we just use them.\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    # Exclude 'filename' as it's not a numerical feature for the model.\n",
    "    # Exclude 'deviation_score' as it's our target variable.\n",
    "    # 'centroid_x_cropped' can be redundant with 'deviation_score' but might add context, let's keep it.\n",
    "    \n",
    "    feature_columns = [\n",
    "        'is_line_detected',\n",
    "        'centroid_x_cropped',\n",
    "        'centroid_y_cropped',\n",
    "        'num_line_segments',\n",
    "        'total_line_pixel_length',\n",
    "        'avg_line_angle_deg',\n",
    "        'std_line_angle_deg',\n",
    "        'min_line_y_cropped',\n",
    "        'max_line_y_cropped',\n",
    "        'fitted_line_slope_deg',\n",
    "        'fitted_line_x_intercept_at_bottom_cropped',\n",
    "        'fitted_line_x_intercept_at_top_cropped'\n",
    "    ]\n",
    "\n",
    "    # Filter out columns that might not exist if data extraction had issues\n",
    "    feature_columns = [col for col in feature_columns if col in df_cleaned.columns]\n",
    "    \n",
    "    X = df_cleaned[feature_columns]\n",
    "    y = df_cleaned['deviation_score']\n",
    "\n",
    "    print(f\"\\nDataset shape after dropping rows with NaN deviation score: {df_cleaned.shape}\")\n",
    "    print(f\"Features (X) shape: {X.shape}, Target (y) shape: {y.shape}\")\n",
    "    print(f\"Features being used: {feature_columns}\")\n",
    "\n",
    "    if X.empty:\n",
    "        print(\"ERROR: No valid data remaining after cleaning. Cannot train the model.\")\n",
    "        exit()\n",
    "\n",
    "    # 3. Data Preprocessing - Scaling Features\n",
    "    # SVR is sensitive to feature scaling.\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(\"\\nFeatures scaled using StandardScaler.\")\n",
    "\n",
    "    # 4. Train-Test Split\n",
    "    # Using a random state for reproducibility\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"Training data shape: {X_train.shape}, Test data shape: {X_test.shape}\")\n",
    "\n",
    "    # 5. SVR Model Training\n",
    "    # SVR with RBF kernel is a good starting point.\n",
    "    # C: Regularization parameter. Higher C means less regularization.\n",
    "    # epsilon: Epsilon-tube within which no penalty is associated in the training loss function.\n",
    "    #          Determines the margin of tolerance.\n",
    "    svr_model = SVR(kernel='linear', C=1.0, epsilon=0.05)\n",
    "    \n",
    "    print(\"\\nTraining SVR model...\")\n",
    "    svr_model.fit(X_train, y_train)\n",
    "    print(\"SVR model training complete.\")\n",
    "\n",
    "    # 6. Evaluation\n",
    "    y_pred = svr_model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n--- Model Evaluation on Test Set ---\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"R-squared (R2) Score: {r2:.4f}\")\n",
    "    print(\"\\nNote: MAE represents the average absolute difference between predicted and actual values.\")\n",
    "    print(\"R-squared indicates the proportion of variance in the target that is predictable from the features.\")\n",
    "\n",
    "    # 7. Model and Scaler Dumping\n",
    "    joblib.dump(svr_model, model_save_path)\n",
    "    joblib.dump(scaler, scaler_save_path)\n",
    "\n",
    "    print(f\"\\n✅ Trained SVR model dumped to: {model_save_path}\")\n",
    "    print(f\"✅ Fitted StandardScaler dumped to: {scaler_save_path}\")\n",
    "    print(\"\\n--- Training Complete ---\")\n",
    "    print(\"You can now load these files in a new script to make predictions on new, unseen data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
