{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c8a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model and scaler loaded successfully.\n",
      "Successfully retrieved feature column order from the loaded scaler.\n",
      "\n",
      "Processing image: 00443870.png\n",
      "\n",
      "Prediction runtime (including feature extraction & scaling): 40.15 ms\n",
      "\n",
      "Prediction for '00443870.png':\n",
      "  Predicted Class: Line on Right\n",
      "  Numerical Label: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# --- Configuration ---\n",
    "image_path =  \"C:/Users/BCI-Lab/Downloads/teamA_dataset/_out_dataset/good_data/00443870.png\"   \n",
    "model_filename = \"svm_line_classifier.joblib\"  # Filename of your saved SVM model\n",
    "scaler_filename = \"scaler_line_features.joblib\"  # Filename of your saved StandardScaler\n",
    "# Removed: training_csv_path = \"line_detection_features.csv\" # No longer needed!\n",
    "\n",
    "# --- USER-DEFINED OPTIMIZED PARAMETERS ---\n",
    "# IMPORTANT: REPLACE THESE VALUES with the \"perfect variables\" you found during tuning!\n",
    "OPTIMIZED_PARAMS = {\n",
    "    \"lower_L\": 137,\n",
    "    \"upper_L\": 255,\n",
    "    \"lower_A\": 134,\n",
    "    \"upper_A\": 161,\n",
    "    \"lower_B\": 138,\n",
    "    \"upper_B\": 165,\n",
    "    \"color_morph_kernel_size\": 3,\n",
    "    \"edge_morph_kernel_size\": 7,\n",
    "    \"canny_thresh1\": 18,\n",
    "    \"canny_thresh2\": 66,\n",
    "    \"hough_threshold\": 57,       # Min votes for a line\n",
    "    \"hough_min_length\": 18,      # Min line length\n",
    "    \"hough_max_gap\": 17,         # Max gap to connect segments\n",
    "    \"crop_percent\": 55,\n",
    "    \"line_center_tolerance_percent\": 10 # Percentage of image width for \"center\" tolerance\n",
    "}\n",
    "\n",
    "# --- 1. Load the Model and Scaler ---\n",
    "try:\n",
    "    loaded_model = joblib.load(model_filename)\n",
    "    loaded_scaler = joblib.load(scaler_filename)\n",
    "    print(\"SVM model and scaler loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model or scaler file not found. Ensure '{model_filename}' and '{scaler_filename}' are in the correct directory.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model or scaler: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- CRITICAL FIX: Get the feature column order directly from the loaded scaler ---\n",
    "# The scaler stores the feature names it was fitted on, ensuring correct order.\n",
    "feature_columns_order = loaded_scaler.feature_names_in_.tolist()\n",
    "print(\"Successfully retrieved feature column order from the loaded scaler.\")\n",
    "\n",
    "\n",
    "# --- 2. Load the Image ---\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    print(f\"Error: Could not read image at '{image_path}'. Please check the path and file integrity.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nProcessing image: {os.path.basename(image_path)}\")\n",
    "\n",
    "# --- 3. Image Processing and Feature Extraction (Identical to training data generation) ---\n",
    "\n",
    "# --- 3.1. Crop from top ---\n",
    "crop_y = int(image.shape[0] * OPTIMIZED_PARAMS[\"crop_percent\"] / 100)\n",
    "if crop_y >= image.shape[0]:\n",
    "    crop_y = image.shape[0] - 1\n",
    "cropped_image = image[crop_y:, :].copy()\n",
    "\n",
    "# Initialize a dictionary to hold features for this single image\n",
    "current_features = {}\n",
    "\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# Handle cases where cropped image might be empty\n",
    "if cropped_image.shape[0] == 0 or cropped_image.shape[1] == 0:\n",
    "    print(f\"Warning: Cropped image for {os.path.basename(image_path)} is empty. Defaulting to 'No Line Detected' features.\")\n",
    "    # Fill with default/zero features as if no line was detected\n",
    "    current_features = {\n",
    "        \"cx\": -1,\n",
    "        \"num_detected_lines\": 0,\n",
    "        \"avg_line_length\": 0,\n",
    "        \"total_line_length\": 0,\n",
    "        \"std_line_length\": 0,\n",
    "        \"avg_line_angle_deg\": 0,\n",
    "        \"std_line_angle_deg\": 0,\n",
    "        \"line_cx_mean\": -1,\n",
    "        \"line_cx_std\": 0,\n",
    "        \"line_cy_mean\": -1,\n",
    "        \"longest_line_length\": 0,\n",
    "        \"longest_line_angle_deg\": 0,\n",
    "        \"mask_pixel_count\": 0,\n",
    "        \"mask_area_ratio\": 0,\n",
    "        \"mask_centroid_x_norm\": 0.5,\n",
    "        \"mask_centroid_y_norm\": 0.5,\n",
    "        \"mask_hu_moment_1\": 0, \"mask_hu_moment_2\": 0, \"mask_hu_moment_3\": 0,\n",
    "        \"mask_hu_moment_4\": 0, \"mask_hu_moment_5\": 0, \"mask_hu_moment_6\": 0, \"mask_hu_moment_7\": 0,\n",
    "        \"color_mask_pixel_count\": 0,\n",
    "        \"color_mask_area_ratio\": 0,\n",
    "        \"is_line_detected_binary\": 0\n",
    "    }\n",
    "else:\n",
    "   \n",
    "    lab_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_cropped)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    l_eq = clahe.apply(l_channel)\n",
    "    lab_eq = cv2.merge([l_eq, a_channel, b_channel])\n",
    "    blurred_lab_eq = cv2.medianBlur(lab_eq, 5)\n",
    "\n",
    "    lower_orange_lab = np.array([OPTIMIZED_PARAMS[\"lower_L\"], OPTIMIZED_PARAMS[\"lower_A\"], OPTIMIZED_PARAMS[\"lower_B\"]])\n",
    "    upper_orange_lab = np.array([OPTIMIZED_PARAMS[\"upper_L\"], OPTIMIZED_PARAMS[\"upper_A\"], OPTIMIZED_PARAMS[\"upper_B\"]])\n",
    "    color_mask = cv2.inRange(blurred_lab_eq, lower_orange_lab, upper_orange_lab)\n",
    "\n",
    "  \n",
    "    color_morph_kernel = np.ones((OPTIMIZED_PARAMS[\"color_morph_kernel_size\"], OPTIMIZED_PARAMS[\"color_morph_kernel_size\"]), np.uint8)\n",
    "    color_mask_morphed = cv2.morphologyEx(color_mask, cv2.MORPH_OPEN, color_morph_kernel, iterations=1)\n",
    "    color_mask_morphed = cv2.dilate(color_mask_morphed, color_morph_kernel, iterations=1)\n",
    "    color_mask_morphed = cv2.morphologyEx(color_mask_morphed, cv2.MORPH_CLOSE, color_morph_kernel, iterations=1)\n",
    "\n",
    "    gray_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_gray = cv2.GaussianBlur(gray_cropped, (5, 5), 0)\n",
    "    edge_mask = cv2.Canny(blurred_gray, OPTIMIZED_PARAMS[\"canny_thresh1\"], OPTIMIZED_PARAMS[\"canny_thresh2\"])\n",
    "\n",
    "   \n",
    "    edge_morph_kernel = np.ones((OPTIMIZED_PARAMS[\"edge_morph_kernel_size\"], OPTIMIZED_PARAMS[\"edge_morph_kernel_size\"]), np.uint8)\n",
    "    edge_mask_morphed = cv2.morphologyEx(edge_mask, cv2.MORPH_CLOSE, edge_morph_kernel, iterations=1)\n",
    "\n",
    "    \n",
    "    final_mask = cv2.bitwise_and(color_mask_morphed, edge_mask_morphed)\n",
    "\n",
    "\n",
    "    lines = cv2.HoughLinesP(final_mask, 1, np.pi / 180,\n",
    "                                OPTIMIZED_PARAMS[\"hough_threshold\"],\n",
    "                                minLineLength=OPTIMIZED_PARAMS[\"hough_min_length\"],\n",
    "                                maxLineGap=OPTIMIZED_PARAMS[\"hough_max_gap\"])\n",
    "\n",
    "    \n",
    "    # Initialize line features\n",
    "    num_detected_lines = 0\n",
    "    avg_line_length = 0\n",
    "    total_line_length = 0\n",
    "    std_line_length = 0\n",
    "    avg_line_angle_deg = 0\n",
    "    std_line_angle_deg = 0\n",
    "    line_cx_mean = -1\n",
    "    line_cx_std = 0\n",
    "    line_cy_mean = -1\n",
    "    longest_line_length = 0\n",
    "    longest_line_angle_deg = 0\n",
    "    is_line_detected_binary = 0\n",
    "    cx = -1 \n",
    "    if lines is not None:\n",
    "        is_line_detected_binary = 1\n",
    "        num_detected_lines = len(lines)\n",
    "\n",
    "        all_line_midpoints_x = []\n",
    "        all_line_midpoints_y = []\n",
    "        line_lengths = []\n",
    "        line_angles_rad = []\n",
    "\n",
    "        max_length_found = 0\n",
    "        angle_of_longest_line = 0\n",
    "\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            line_lengths.append(length)\n",
    "\n",
    "            if length > max_length_found:\n",
    "                max_length_found = length\n",
    "                angle_of_longest_line = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "\n",
    "            angle_rad = np.arctan2(y2 - y1, x2 - x1)\n",
    "            line_angles_rad.append(angle_rad)\n",
    "\n",
    "            mid_x = (x1 + x2) // 2\n",
    "            mid_y = (y1 + y2) // 2\n",
    "            all_line_midpoints_x.append(mid_x)\n",
    "            all_line_midpoints_y.append(mid_y)\n",
    "\n",
    "        if line_lengths:\n",
    "            avg_line_length = np.mean(line_lengths)\n",
    "            total_line_length = np.sum(line_lengths)\n",
    "            std_line_length = np.std(line_lengths) if len(line_lengths) > 1 else 0\n",
    "            longest_line_length = max_length_found\n",
    "            longest_line_angle_deg = angle_of_longest_line\n",
    "\n",
    "        if all_line_midpoints_x:\n",
    "            cx = int(np.mean(all_line_midpoints_x)) # This cx is used for the label mapping\n",
    "            line_cx_mean = cx\n",
    "            line_cx_std = np.std(all_line_midpoints_x) if len(all_line_midpoints_x) > 1 else 0\n",
    "            line_cy_mean = int(np.mean(all_line_midpoints_y))\n",
    "\n",
    "        if line_angles_rad:\n",
    "            normalized_angles_deg = [angle % 180 for angle in np.degrees(line_angles_rad)]\n",
    "            avg_line_angle_deg = np.mean(normalized_angles_deg)\n",
    "            std_line_angle_deg = np.std(normalized_angles_deg) if len(normalized_angles_deg) > 1 else 0\n",
    "\n",
    "    # Features from Final Mask\n",
    "    mask_pixel_count = np.sum(final_mask > 0)\n",
    "    mask_area_ratio = mask_pixel_count / (final_mask.shape[0] * final_mask.shape[1]) if (final_mask.shape[0] * final_mask.shape[1]) > 0 else 0\n",
    "\n",
    "    M = cv2.moments(final_mask)\n",
    "    mask_centroid_x_norm = 0.5\n",
    "    mask_centroid_y_norm = 0.5\n",
    "    hu_moments = np.zeros(7) # Initialize to zeros\n",
    "    if M[\"m00\"] != 0:\n",
    "        mask_centroid_x = M[\"m10\"] / M[\"m00\"]\n",
    "        mask_centroid_y = M[\"m01\"] / M[\"m00\"]\n",
    "        mask_centroid_x_norm = mask_centroid_x / final_mask.shape[1]\n",
    "        mask_centroid_y_norm = mask_centroid_y / final_mask.shape[0]\n",
    "        hu_moments = cv2.HuMoments(M).flatten()\n",
    "    \n",
    "    # Features from Morphed Color Mask\n",
    "    color_mask_pixel_count = np.sum(color_mask_morphed > 0)\n",
    "    color_mask_area_ratio = color_mask_pixel_count / (color_mask_morphed.shape[0] * color_mask_morphed.shape[1]) if (color_mask_morphed.shape[0] * color_mask_morphed.shape[1]) > 0 else 0\n",
    "\n",
    "    # Store all features for this image in a dictionary\n",
    "    current_features = {\n",
    "        \"cx\": cx,\n",
    "        \"num_detected_lines\": num_detected_lines,\n",
    "        \"avg_line_length\": avg_line_length,\n",
    "        \"total_line_length\": total_line_length,\n",
    "        \"std_line_length\": std_line_length,\n",
    "        \"avg_line_angle_deg\": avg_line_angle_deg,\n",
    "        \"std_line_angle_deg\": std_line_angle_deg,\n",
    "        \"line_cx_mean\": line_cx_mean,\n",
    "        \"line_cx_std\": line_cx_std,\n",
    "        \"line_cy_mean\": line_cy_mean,\n",
    "        \"longest_line_length\": longest_line_length,\n",
    "        \"longest_line_angle_deg\": longest_line_angle_deg,\n",
    "        \"mask_pixel_count\": mask_pixel_count,\n",
    "        \"mask_area_ratio\": mask_area_ratio,\n",
    "        \"mask_centroid_x_norm\": mask_centroid_x_norm,\n",
    "        \"mask_centroid_y_norm\": mask_centroid_y_norm,\n",
    "        \"mask_hu_moment_1\": hu_moments[0], \"mask_hu_moment_2\": hu_moments[1], \"mask_hu_moment_3\": hu_moments[2],\n",
    "        \"mask_hu_moment_4\": hu_moments[3], \"mask_hu_moment_5\": hu_moments[4], \"mask_hu_moment_6\": hu_moments[5], \"mask_hu_moment_7\": hu_moments[6],\n",
    "        \"color_mask_pixel_count\": color_mask_pixel_count,\n",
    "        \"color_mask_area_ratio\": color_mask_area_ratio,\n",
    "        \"is_line_detected_binary\": is_line_detected_binary\n",
    "    }\n",
    "\n",
    "# Convert the dictionary to a DataFrame, ensuring the correct column order\n",
    "input_features = pd.DataFrame([current_features])\n",
    "# CRITICAL FIX: Reindex to match training order, using feature_columns_order from the scaler\n",
    "input_features = input_features[feature_columns_order]\n",
    "\n",
    "# --- 4. Scale the Features ---\n",
    "# Use the loaded scaler to transform the new input features\n",
    "input_features_scaled = loaded_scaler.transform(input_features)\n",
    "\n",
    "# --- 5. Make the Prediction ---\n",
    "# The predict method returns an array, so take the first element [0]\n",
    "prediction = loaded_model.predict(input_features_scaled)[0]\n",
    "\n",
    "# --- 6. Output the Prediction ---\n",
    "# Map the numerical prediction back to a human-readable label\n",
    "label_map = {-1: \"Line on Left\", 0: \"Line in Center\", 1: \"Line on Right\", 2: \"No Line Detected\"}\n",
    "predicted_label_text = label_map.get(prediction, \"Unknown Label\")\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "# --- Calculate and print runtime ---\n",
    "runtime_ms = (end_time - start_time) * 1000\n",
    "print(f\"\\nPrediction runtime (including feature extraction & scaling): {runtime_ms:.2f} ms\")\n",
    "\n",
    "\n",
    "print(f\"\\nPrediction for '{os.path.basename(image_path)}':\")\n",
    "print(f\"  Predicted Class: {predicted_label_text}\")\n",
    "print(f\"  Numerical Label: {prediction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709bb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model and scaler loaded successfully.\n",
      "Successfully retrieved feature column order from the loaded scaler.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and load model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "model_filename = \"svm_line_classifier.joblib\"\n",
    "scaler_filename = \"scaler_line_features.joblib\"\n",
    "\n",
    "OPTIMIZED_PARAMS = {\n",
    "    \"lower_L\": 137,\n",
    "    \"upper_L\": 255,\n",
    "    \"lower_A\": 134,\n",
    "    \"upper_A\": 161,\n",
    "    \"lower_B\": 138,\n",
    "    \"upper_B\": 165,\n",
    "    \"color_morph_kernel_size\": 3,\n",
    "    \"edge_morph_kernel_size\": 7,\n",
    "    \"canny_thresh1\": 18,\n",
    "    \"canny_thresh2\": 66,\n",
    "    \"hough_threshold\": 57,\n",
    "    \"hough_min_length\": 18,\n",
    "    \"hough_max_gap\": 17,\n",
    "    \"crop_percent\": 55,\n",
    "    \"line_center_tolerance_percent\": 10\n",
    "}\n",
    "\n",
    "try:\n",
    "    loaded_model = joblib.load(model_filename)\n",
    "    loaded_scaler = joblib.load(scaler_filename)\n",
    "    print(\"SVM model and scaler loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model or scaler file not found. Ensure '{model_filename}' and '{scaler_filename}' are in the correct directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model or scaler: {e}\")\n",
    "\n",
    "feature_columns_order = loaded_scaler.feature_names_in_.tolist()\n",
    "print(\"Successfully retrieved feature column order from the loaded scaler.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f1fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d6a2ec758244a68c0f98fd0153cef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Image:', options=(('00420478.png', 'C:/Users/BCI-Lab/Downloads/teamA_dataset/_outâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1291 images in the directory.\n"
     ]
    }
   ],
   "source": [
    "# Image selection\n",
    "def get_images_from_directory(directory_path):\n",
    "    image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']\n",
    "    images = []\n",
    "    if os.path.exists(directory_path):\n",
    "        for file in os.listdir(directory_path):\n",
    "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                images.append(os.path.join(directory_path, file))\n",
    "    return sorted(images)\n",
    "\n",
    "dataset_path = \"C:/Users/BCI-Lab/Downloads/teamA_dataset/_out_dataset/good_data/\"\n",
    "available_images = get_images_from_directory(dataset_path)\n",
    "\n",
    "if available_images:\n",
    "    image_dropdown = widgets.Dropdown(\n",
    "        options=[(os.path.basename(img), img) for img in available_images],\n",
    "        description='Select Image:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    display(image_dropdown)\n",
    "    print(f\"Found {len(available_images)} images in the directory.\")\n",
    "else:\n",
    "    print(\"No images found in the specified directory.\")\n",
    "    image_dropdown = widgets.Text(\n",
    "        placeholder='Enter full path to image file',\n",
    "        description='Image Path:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    display(image_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process selected image\n",
    "def process_image():\n",
    "    if hasattr(image_dropdown, 'value'):\n",
    "        if isinstance(image_dropdown.value, str) and image_dropdown.value:\n",
    "            image_path = image_dropdown.value\n",
    "        else:\n",
    "            print(\"Please select an image first.\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"Please run Cell 2 first to select an image.\")\n",
    "        return\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Could not read image at '{image_path}'. Please check the path and file integrity.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nProcessing image: {os.path.basename(image_path)}\")\n",
    "\n",
    "    crop_y = int(image.shape[0] * OPTIMIZED_PARAMS[\"crop_percent\"] / 100)\n",
    "    if crop_y >= image.shape[0]:\n",
    "        crop_y = image.shape[0] - 1\n",
    "    cropped_image = image[crop_y:, :].copy()\n",
    "\n",
    "    current_features = {}\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    if cropped_image.shape[0] == 0 or cropped_image.shape[1] == 0:\n",
    "        print(f\"Warning: Cropped image for {os.path.basename(image_path)} is empty. Defaulting to 'No Line Detected' features.\")\n",
    "        current_features = {\n",
    "            \"cx\": -1,\n",
    "            \"num_detected_lines\": 0,\n",
    "            \"avg_line_length\": 0,\n",
    "            \"total_line_length\": 0,\n",
    "            \"std_line_length\": 0,\n",
    "            \"avg_line_angle_deg\": 0,\n",
    "            \"std_line_angle_deg\": 0,\n",
    "            \"line_cx_mean\": -1,\n",
    "            \"line_cx_std\": 0,\n",
    "            \"line_cy_mean\": -1,\n",
    "            \"longest_line_length\": 0,\n",
    "            \"longest_line_angle_deg\": 0,\n",
    "            \"mask_pixel_count\": 0,\n",
    "            \"mask_area_ratio\": 0,\n",
    "            \"mask_centroid_x_norm\": 0.5,\n",
    "            \"mask_centroid_y_norm\": 0.5,\n",
    "            \"mask_hu_moment_1\": 0, \"mask_hu_moment_2\": 0, \"mask_hu_moment_3\": 0,\n",
    "            \"mask_hu_moment_4\": 0, \"mask_hu_moment_5\": 0, \"mask_hu_moment_6\": 0, \"mask_hu_moment_7\": 0,\n",
    "            \"color_mask_pixel_count\": 0,\n",
    "            \"color_mask_area_ratio\": 0,\n",
    "            \"is_line_detected_binary\": 0\n",
    "        }\n",
    "    else:\n",
    "        lab_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2LAB)\n",
    "        l_channel, a_channel, b_channel = cv2.split(lab_cropped)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        l_eq = clahe.apply(l_channel)\n",
    "        lab_eq = cv2.merge([l_eq, a_channel, b_channel])\n",
    "        blurred_lab_eq = cv2.medianBlur(lab_eq, 5)\n",
    "\n",
    "        lower_orange_lab = np.array([OPTIMIZED_PARAMS[\"lower_L\"], OPTIMIZED_PARAMS[\"lower_A\"], OPTIMIZED_PARAMS[\"lower_B\"]])\n",
    "        upper_orange_lab = np.array([OPTIMIZED_PARAMS[\"upper_L\"], OPTIMIZED_PARAMS[\"upper_A\"], OPTIMIZED_PARAMS[\"upper_B\"]])\n",
    "        color_mask = cv2.inRange(blurred_lab_eq, lower_orange_lab, upper_orange_lab)\n",
    "\n",
    "        color_morph_kernel = np.ones((OPTIMIZED_PARAMS[\"color_morph_kernel_size\"], OPTIMIZED_PARAMS[\"color_morph_kernel_size\"]), np.uint8)\n",
    "        color_mask_morphed = cv2.morphologyEx(color_mask, cv2.MORPH_OPEN, color_morph_kernel, iterations=1)\n",
    "        color_mask_morphed = cv2.dilate(color_mask_morphed, color_morph_kernel, iterations=1)\n",
    "        color_mask_morphed = cv2.morphologyEx(color_mask_morphed, cv2.MORPH_CLOSE, color_morph_kernel, iterations=1)\n",
    "\n",
    "        gray_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred_gray = cv2.GaussianBlur(gray_cropped, (5, 5), 0)\n",
    "        edge_mask = cv2.Canny(blurred_gray, OPTIMIZED_PARAMS[\"canny_thresh1\"], OPTIMIZED_PARAMS[\"canny_thresh2\"])\n",
    "\n",
    "        edge_morph_kernel = np.ones((OPTIMIZED_PARAMS[\"edge_morph_kernel_size\"], OPTIMIZED_PARAMS[\"edge_morph_kernel_size\"]), np.uint8)\n",
    "        edge_mask_morphed = cv2.morphologyEx(edge_mask, cv2.MORPH_CLOSE, edge_morph_kernel, iterations=1)\n",
    "\n",
    "        final_mask = cv2.bitwise_and(color_mask_morphed, edge_mask_morphed)\n",
    "\n",
    "        lines = cv2.HoughLinesP(final_mask, 1, np.pi / 180,\n",
    "                                    OPTIMIZED_PARAMS[\"hough_threshold\"],\n",
    "                                    minLineLength=OPTIMIZED_PARAMS[\"hough_min_length\"],\n",
    "                                    maxLineGap=OPTIMIZED_PARAMS[\"hough_max_gap\"])\n",
    "\n",
    "        num_detected_lines = 0\n",
    "        avg_line_length = 0\n",
    "        total_line_length = 0\n",
    "        std_line_length = 0\n",
    "        avg_line_angle_deg = 0\n",
    "        std_line_angle_deg = 0\n",
    "        line_cx_mean = -1\n",
    "        line_cx_std = 0\n",
    "        line_cy_mean = -1\n",
    "        longest_line_length = 0\n",
    "        longest_line_angle_deg = 0\n",
    "        is_line_detected_binary = 0\n",
    "        cx = -1\n",
    "\n",
    "        if lines is not None:\n",
    "            is_line_detected_binary = 1\n",
    "            num_detected_lines = len(lines)\n",
    "\n",
    "            all_line_midpoints_x = []\n",
    "            all_line_midpoints_y = []\n",
    "            line_lengths = []\n",
    "            line_angles_rad = []\n",
    "\n",
    "            max_length_found = 0\n",
    "            angle_of_longest_line = 0\n",
    "\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "                length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "                line_lengths.append(length)\n",
    "\n",
    "                if length > max_length_found:\n",
    "                    max_length_found = length\n",
    "                    angle_of_longest_line = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "\n",
    "                angle_rad = np.arctan2(y2 - y1, x2 - x1)\n",
    "                line_angles_rad.append(angle_rad)\n",
    "\n",
    "                mid_x = (x1 + x2) // 2\n",
    "                mid_y = (y1 + y2) // 2\n",
    "                all_line_midpoints_x.append(mid_x)\n",
    "                all_line_midpoints_y.append(mid_y)\n",
    "\n",
    "            if line_lengths:\n",
    "                avg_line_length = np.mean(line_lengths)\n",
    "                total_line_length = np.sum(line_lengths)\n",
    "                std_line_length = np.std(line_lengths) if len(line_lengths) > 1 else 0\n",
    "                longest_line_length = max_length_found\n",
    "                longest_line_angle_deg = angle_of_longest_line\n",
    "\n",
    "            if all_line_midpoints_x:\n",
    "                cx = int(np.mean(all_line_midpoints_x))\n",
    "                line_cx_mean = cx\n",
    "                line_cx_std = np.std(all_line_midpoints_x) if len(all_line_midpoints_x) > 1 else 0\n",
    "                line_cy_mean = int(np.mean(all_line_midpoints_y))\n",
    "\n",
    "            if line_angles_rad:\n",
    "                normalized_angles_deg = [angle % 180 for angle in np.degrees(line_angles_rad)]\n",
    "                avg_line_angle_deg = np.mean(normalized_angles_deg)\n",
    "                std_line_angle_deg = np.std(normalized_angles_deg) if len(normalized_angles_deg) > 1 else 0\n",
    "\n",
    "        mask_pixel_count = np.sum(final_mask > 0)\n",
    "        mask_area_ratio = mask_pixel_count / (final_mask.shape[0] * final_mask.shape[1]) if (final_mask.shape[0] * final_mask.shape[1]) > 0 else 0\n",
    "\n",
    "        M = cv2.moments(final_mask)\n",
    "        mask_centroid_x_norm = 0.5\n",
    "        mask_centroid_y_norm = 0.5\n",
    "        hu_moments = np.zeros(7)\n",
    "        if M[\"m00\"] != 0:\n",
    "            mask_centroid_x = M[\"m10\"] / M[\"m00\"]\n",
    "            mask_centroid_y = M[\"m01\"] / M[\"m00\"]\n",
    "            mask_centroid_x_norm = mask_centroid_x / final_mask.shape[1]\n",
    "            mask_centroid_y_norm = mask_centroid_y / final_mask.shape[0]\n",
    "            hu_moments = cv2.HuMoments(M).flatten()\n",
    "        \n",
    "        color_mask_pixel_count = np.sum(color_mask_morphed > 0)\n",
    "        color_mask_area_ratio = color_mask_pixel_count / (color_mask_morphed.shape[0] * color_mask_morphed.shape[1]) if (color_mask_morphed.shape[0] * color_mask_morphed.shape[1]) > 0 else 0\n",
    "\n",
    "        current_features = {\n",
    "            \"cx\": cx,\n",
    "            \"num_detected_lines\": num_detected_lines,\n",
    "            \"avg_line_length\": avg_line_length,\n",
    "            \"total_line_length\": total_line_length,\n",
    "            \"std_line_length\": std_line_length,\n",
    "            \"avg_line_angle_deg\": avg_line_angle_deg,\n",
    "            \"std_line_angle_deg\": std_line_angle_deg,\n",
    "            \"line_cx_mean\": line_cx_mean,\n",
    "            \"line_cx_std\": line_cx_std,\n",
    "            \"line_cy_mean\": line_cy_mean,\n",
    "            \"longest_line_length\": longest_line_length,\n",
    "            \"longest_line_angle_deg\": longest_line_angle_deg,\n",
    "            \"mask_pixel_count\": mask_pixel_count,\n",
    "            \"mask_area_ratio\": mask_area_ratio,\n",
    "            \"mask_centroid_x_norm\": mask_centroid_x_norm,\n",
    "            \"mask_centroid_y_norm\": mask_centroid_y_norm,\n",
    "            \"mask_hu_moment_1\": hu_moments[0], \"mask_hu_moment_2\": hu_moments[1], \"mask_hu_moment_3\": hu_moments[2],\n",
    "            \"mask_hu_moment_4\": hu_moments[3], \"mask_hu_moment_5\": hu_moments[4], \"mask_hu_moment_6\": hu_moments[5], \"mask_hu_moment_7\": hu_moments[6],\n",
    "            \"color_mask_pixel_count\": color_mask_pixel_count,\n",
    "            \"color_mask_area_ratio\": color_mask_area_ratio,\n",
    "            \"is_line_detected_binary\": is_line_detected_binary\n",
    "        }\n",
    "\n",
    "    input_features = pd.DataFrame([current_features])\n",
    "    input_features = input_features[feature_columns_order]\n",
    "\n",
    "    input_features_scaled = loaded_scaler.transform(input_features)\n",
    "\n",
    "    prediction = loaded_model.predict(input_features_scaled)[0]\n",
    "\n",
    "    label_map = {-1: \"Line on Left\", 0: \"Line in Center\", 1: \"Line on Right\", 2: \"No Line Detected\"}\n",
    "    predicted_label_text = label_map.get(prediction, \"Unknown Label\")\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    runtime_ms = (end_time - start_time) * 1000\n",
    "    print(f\"\\nPrediction runtime (including feature extraction & scaling): {runtime_ms:.2f} ms\")\n",
    "\n",
    "    print(f\"\\nPrediction for '{os.path.basename(image_path)}':\")\n",
    "    print(f\"  Predicted Class: {predicted_label_text}\")\n",
    "    print(f\"  Numerical Label: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06badf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image: 00425599.png\n",
      "\n",
      "Prediction runtime (including feature extraction & scaling): 39.60 ms\n",
      "\n",
      "Prediction for '00425599.png':\n",
      "  Predicted Class: Line in Center\n",
      "  Numerical Label: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "process_image()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
