{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9845201",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 51) (484111990.py, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 51\u001b[1;36m\u001b[0m\n\u001b[1;33m    It's good practice to store your model and scalers in a dedicated directory. Let's create one if it doesn't exist.\u001b[0m\n\u001b[1;37m                                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 51)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib # Import joblib at the top with other imports\n",
    "import os     # Import os for path manipulation\n",
    "\n",
    "# --- 1. Load your Data ---\n",
    "path = r'D:\\Autonomous Systems A\\Truck-Platooning-Simulation-CARLA\\Computer vision model\\line_detection_features.csv'\n",
    "data = pd.read_csv(path)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- 2. Define Features (X) and Continuous Target (y) ---\n",
    "continuous_target_column = 'cx'\n",
    "\n",
    "feature_columns = [col for col in df.columns if col not in ['filename', 'line_label', continuous_target_column]]\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[continuous_target_column]\n",
    "\n",
    "# --- 3. Split data into training and testing sets ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- 4. Scale Input Features (X) ---\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# --- 5. Scale Target Variable (y) to the range [-1, 1] ---\n",
    "scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# --- 6. Train the SVR model ---\n",
    "# Note: You changed kernel to 'linear'. Keep 'rbf' if it gave better previous results.\n",
    "svr_model = SVR(kernel='linear', C=10.0, epsilon=0.05, gamma='scale')\n",
    "svr_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# --- 7. Make predictions ---\n",
    "y_pred_scaled = svr_model.predict(X_test_scaled)\n",
    "\n",
    "# --- Evaluate the model ---\n",
    "print(f\"Mean Absolute Error (scaled): {mean_absolute_error(y_test_scaled, y_pred_scaled):.4f}\")\n",
    "print(f\"R-squared (scaled): {r2_score(y_test_scaled, y_pred_scaled):.4f}\")\n",
    "\n",
    "---\n",
    "\n",
    "### Saving the Model and Scalers\n",
    "\n",
    "# Create a directory to save models and scalers if it doesn't exist\n",
    "save_dir = 'trained_models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths for the model and scalers\n",
    "model_path = os.path.join(save_dir, 'svr_line_position_model.joblib')\n",
    "scaler_X_path = os.path.join(save_dir, 'scaler_X.joblib')\n",
    "scaler_y_path = os.path.join(save_dir, 'scaler_y.joblib')\n",
    "\n",
    "# Save the SVR model\n",
    "joblib.dump(svr_model, model_path)\n",
    "print(f\"SVR Model saved successfully to '{model_path}'\")\n",
    "\n",
    "# Save the StandardScaler for features\n",
    "joblib.dump(scaler_X, scaler_X_path)\n",
    "print(f\"Features StandardScaler saved successfully to '{scaler_X_path}'\")\n",
    "\n",
    "# Save the MinMaxScaler for the target variable\n",
    "joblib.dump(scaler_y, scaler_y_path)\n",
    "print(f\"Target MinMaxScaler saved successfully to '{scaler_y_path}'\")\n",
    "\n",
    "print(\"\\nAll components (model and scalers) necessary for future predictions have been saved.\")\n",
    "\n",
    "# --- How to Load Them Back for New Predictions ---\n",
    "# In a new script or session, you would load them like this:\n",
    "# loaded_svr_model = joblib.load(model_path)\n",
    "# loaded_scaler_X = joblib.load(scaler_X_path)\n",
    "# loaded_scaler_y = joblib.load(scaler_y_path)\n",
    "\n",
    "# Then, to make a new prediction:\n",
    "# new_raw_features = pd.DataFrame([[...]], columns=feature_columns) # Replace with your actual new data\n",
    "# new_features_scaled = loaded_scaler_X.transform(new_raw_features)\n",
    "# predicted_position_scaled = loaded_svr_model.predict(new_features_scaled)\n",
    "# predicted_position_original_scale = loaded_scaler_y.inverse_transform(predicted_position_scaled.reshape(-1, 1)).flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
