{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d214a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM regression model and both scalers (features and target) loaded successfully.\n",
      "Successfully retrieved feature column order from the loaded feature scaler.\n",
      "\n",
      "Processing image: 00469872.png\n",
      "   Info: No line detected by OpenCV. Setting scaled prediction value to 0.0.\n",
      "\n",
      "Prediction runtime (feature extraction, scaling, prediction, inv. transform, override): 7.33 ms\n",
      "\n",
      "Prediction for '00469872.png':\n",
      "   Feature 'is_line_detected_binary': 0.0\n",
      "   Scaled Prediction Value (cx, from model/override): 0.0000\n",
      "   Predicted Value (cx, original scale after inverse transform/override): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# --- Configuration ---\n",
    "image_path = \"C:/Users/BCI-Lab/Downloads/teamA_dataset/_out_dataset/good_data/00469872.png\" # Example image path\n",
    "# !!! IMPORTANT: Update these filenames for your regression model and scalers !!!\n",
    "regression_model_filename = \"svr_line_position_model.joblib\" # Updated model filename\n",
    "feature_scaler_filename = \"scaler_X.joblib\" # Scaler for input features (X)\n",
    "target_scaler_filename = \"scaler_y.joblib\" # Scaler for target variable (t)\n",
    "\n",
    "# --- USER-DEFINED OPTIMIZED PARAMETERS ---\n",
    "# These parameters are used for feature extraction.\n",
    "# Ensure they are appropriate for the features your regression model was trained on.\n",
    "OPTIMIZED_PARAMS = {\n",
    "    \"lower_L\": 137,\n",
    "    \"upper_L\": 255,\n",
    "    \"lower_A\": 134,\n",
    "    \"upper_A\": 161,\n",
    "    \"lower_B\": 138,\n",
    "    \"upper_B\": 165,\n",
    "    \"color_morph_kernel_size\": 3,\n",
    "    \"edge_morph_kernel_size\": 7,\n",
    "    \"canny_thresh1\": 18,\n",
    "    \"canny_thresh2\": 66,\n",
    "    \"hough_threshold\": 57,      # Min votes for a line\n",
    "    \"hough_min_length\": 18,     # Min line length\n",
    "    \"hough_max_gap\": 17,        # Max gap to connect segments\n",
    "    \"crop_percent\": 55,\n",
    "    \"line_center_tolerance_percent\": 10 # Percentage of image width for \"center\" tolerance (if used in features)\n",
    "}\n",
    "\n",
    "# --- 1. Load the Regression Model and Scalers ---\n",
    "try:\n",
    "    loaded_model = joblib.load(regression_model_filename)\n",
    "    loaded_feature_scaler = joblib.load(feature_scaler_filename)\n",
    "    loaded_target_scaler = joblib.load(target_scaler_filename)\n",
    "    print(\"SVM regression model and both scalers (features and target) loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model or scaler file not found. Ensure '{regression_model_filename}', '{feature_scaler_filename}', and '{target_scaler_filename}' are in the correct directory.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model or scalers: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Get the feature column order directly from the loaded feature scaler ---\n",
    "try:\n",
    "    feature_columns_order = loaded_feature_scaler.feature_names_in_.tolist()\n",
    "    print(\"Successfully retrieved feature column order from the loaded feature scaler.\")\n",
    "except AttributeError:\n",
    "    print(\"Error: The loaded feature scaler does not have 'feature_names_in_'. This attribute is expected.\")\n",
    "    print(\"Please ensure the feature scaler was fitted on a Pandas DataFrame with feature names.\")\n",
    "    print(\"Alternatively, you might need to manually define 'feature_columns_order' if this attribute is not available.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while retrieving feature names from the feature scaler: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 2. Load the Image ---\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    print(f\"Error: Could not read image at '{image_path}'. Please check the path and file integrity.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nProcessing image: {os.path.basename(image_path)}\")\n",
    "\n",
    "# --- 3. Image Processing and Feature Extraction ---\n",
    "\n",
    "# --- 3.1. Crop from top ---\n",
    "crop_y = int(image.shape[0] * OPTIMIZED_PARAMS[\"crop_percent\"] / 100)\n",
    "if crop_y >= image.shape[0]:\n",
    "    crop_y = max(0, image.shape[0] - 1)\n",
    "\n",
    "cropped_image = image[crop_y:, :].copy()\n",
    "\n",
    "current_features = {} # This dictionary will store features for the current image\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "if cropped_image.shape[0] == 0 or cropped_image.shape[1] == 0:\n",
    "    print(f\"Warning: Cropped image for {os.path.basename(image_path)} is empty. Defaulting to 'No Line Detected' equivalent features.\")\n",
    "    # Ensure all keys expected by feature_columns_order are present\n",
    "    current_features = {\n",
    "        \"cx\": -1.0, \"num_detected_lines\": 0.0, \"avg_line_length\": 0.0, \"total_line_length\": 0.0,\n",
    "        \"std_line_length\": 0.0, \"avg_line_angle_deg\": 0.0, \"std_line_angle_deg\": 0.0,\n",
    "        \"line_cx_mean\": -1.0, \"line_cx_std\": 0.0, \"line_cy_mean\": -1.0, \"longest_line_length\": 0.0,\n",
    "        \"longest_line_angle_deg\": 0.0, \"mask_pixel_count\": 0.0, \"mask_area_ratio\": 0.0,\n",
    "        \"mask_centroid_x_norm\": 0.5, \"mask_centroid_y_norm\": 0.5,\n",
    "        \"mask_hu_moment_1\": 0.0, \"mask_hu_moment_2\": 0.0, \"mask_hu_moment_3\": 0.0,\n",
    "        \"mask_hu_moment_4\": 0.0, \"mask_hu_moment_5\": 0.0, \"mask_hu_moment_6\": 0.0, \"mask_hu_moment_7\": 0.0,\n",
    "        \"color_mask_pixel_count\": 0.0, \"color_mask_area_ratio\": 0.0, \"is_line_detected_binary\": 0.0\n",
    "    }\n",
    "else:\n",
    "    lab_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_cropped)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    l_eq = clahe.apply(l_channel)\n",
    "    lab_eq = cv2.merge([l_eq, a_channel, b_channel])\n",
    "    blurred_lab_eq = cv2.medianBlur(lab_eq, 5)\n",
    "\n",
    "    lower_orange_lab = np.array([OPTIMIZED_PARAMS[\"lower_L\"], OPTIMIZED_PARAMS[\"lower_A\"], OPTIMIZED_PARAMS[\"lower_B\"]])\n",
    "    upper_orange_lab = np.array([OPTIMIZED_PARAMS[\"upper_L\"], OPTIMIZED_PARAMS[\"upper_A\"], OPTIMIZED_PARAMS[\"upper_B\"]])\n",
    "    color_mask = cv2.inRange(blurred_lab_eq, lower_orange_lab, upper_orange_lab)\n",
    "\n",
    "    color_morph_kernel_size = OPTIMIZED_PARAMS[\"color_morph_kernel_size\"]\n",
    "    color_morph_kernel = np.ones((color_morph_kernel_size, color_morph_kernel_size), np.uint8)\n",
    "    color_mask_morphed = cv2.morphologyEx(color_mask, cv2.MORPH_OPEN, color_morph_kernel, iterations=1)\n",
    "    color_mask_morphed = cv2.dilate(color_mask_morphed, color_morph_kernel, iterations=1)\n",
    "    color_mask_morphed = cv2.morphologyEx(color_mask_morphed, cv2.MORPH_CLOSE, color_morph_kernel, iterations=1)\n",
    "\n",
    "    gray_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_gray = cv2.GaussianBlur(gray_cropped, (5, 5), 0)\n",
    "    edge_mask = cv2.Canny(blurred_gray, OPTIMIZED_PARAMS[\"canny_thresh1\"], OPTIMIZED_PARAMS[\"canny_thresh2\"])\n",
    "\n",
    "    edge_morph_kernel_size = OPTIMIZED_PARAMS[\"edge_morph_kernel_size\"]\n",
    "    edge_morph_kernel = np.ones((edge_morph_kernel_size, edge_morph_kernel_size), np.uint8)\n",
    "    edge_mask_morphed = cv2.morphologyEx(edge_mask, cv2.MORPH_CLOSE, edge_morph_kernel, iterations=1)\n",
    "\n",
    "    final_mask = cv2.bitwise_and(color_mask_morphed, edge_mask_morphed)\n",
    "\n",
    "    lines = cv2.HoughLinesP(final_mask, 1, np.pi / 180,\n",
    "                            OPTIMIZED_PARAMS[\"hough_threshold\"],\n",
    "                            minLineLength=OPTIMIZED_PARAMS[\"hough_min_length\"],\n",
    "                            maxLineGap=OPTIMIZED_PARAMS[\"hough_max_gap\"])\n",
    "\n",
    "    # Initialize features with default \"no line\" values\n",
    "    num_detected_lines = 0.0\n",
    "    avg_line_length = 0.0; total_line_length = 0.0; std_line_length = 0.0\n",
    "    avg_line_angle_deg = 0.0; std_line_angle_deg = 0.0\n",
    "    line_cx_mean = -1.0; line_cx_std = 0.0; line_cy_mean = -1.0 # Use -1 as a placeholder for \"not applicable\" or \"not found\"\n",
    "    longest_line_length = 0.0; longest_line_angle_deg = 0.0\n",
    "    is_line_detected_binary = 0.0 # 0 for no line, 1 for line detected\n",
    "    cx = -1.0 # Overall center of detected lines, -1 if no lines\n",
    "\n",
    "    if lines is not None:\n",
    "        is_line_detected_binary = 1.0\n",
    "        num_detected_lines = float(len(lines))\n",
    "        all_line_midpoints_x, all_line_midpoints_y, line_lengths, line_angles_rad = [], [], [], []\n",
    "        max_length_found, angle_of_longest_line = 0.0, 0.0\n",
    "\n",
    "        for line_segment in lines:\n",
    "            x1, y1, x2, y2 = line_segment[0]\n",
    "            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            line_lengths.append(length)\n",
    "            if length > max_length_found:\n",
    "                max_length_found = length\n",
    "                angle_of_longest_line = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "            line_angles_rad.append(np.arctan2(y2 - y1, x2 - x1))\n",
    "            all_line_midpoints_x.append((x1 + x2) / 2.0)\n",
    "            all_line_midpoints_y.append((y1 + y2) / 2.0)\n",
    "\n",
    "        if line_lengths: # Check if list is not empty\n",
    "            avg_line_length = np.mean(line_lengths)\n",
    "            total_line_length = np.sum(line_lengths)\n",
    "            std_line_length = np.std(line_lengths) if len(line_lengths) > 1 else 0.0\n",
    "            longest_line_length = max_length_found\n",
    "            longest_line_angle_deg = angle_of_longest_line\n",
    "        if all_line_midpoints_x: # Check if list is not empty\n",
    "            cx = np.mean(all_line_midpoints_x) # This is the primary 'cx' feature\n",
    "            line_cx_mean = cx\n",
    "            line_cx_std = np.std(all_line_midpoints_x) if len(all_line_midpoints_x) > 1 else 0.0\n",
    "            line_cy_mean = np.mean(all_line_midpoints_y)\n",
    "        if line_angles_rad: # Check if list is not empty\n",
    "            normalized_angles_deg = [angle % 180 for angle in np.degrees(line_angles_rad)]\n",
    "            avg_line_angle_deg = np.mean(normalized_angles_deg)\n",
    "            std_line_angle_deg = np.std(normalized_angles_deg) if len(normalized_angles_deg) > 1 else 0.0\n",
    "    \n",
    "    # Features from the final combined mask\n",
    "    mask_pixel_count = float(np.sum(final_mask > 0))\n",
    "    mask_area_ratio = mask_pixel_count / (final_mask.shape[0] * final_mask.shape[1]) if (final_mask.shape[0] * final_mask.shape[1]) > 0 else 0.0\n",
    "    \n",
    "    M = cv2.moments(final_mask)\n",
    "    mask_centroid_x_norm, mask_centroid_y_norm = 0.5, 0.5 # Default to center\n",
    "    hu_moments = np.zeros(7) # Initialize Hu Moments to zeros\n",
    "    if M[\"m00\"] != 0:\n",
    "        mask_centroid_x = M[\"m10\"] / M[\"m00\"]\n",
    "        mask_centroid_y = M[\"m01\"] / M[\"m00\"]\n",
    "        if final_mask.shape[1] > 0: mask_centroid_x_norm = mask_centroid_x / final_mask.shape[1]\n",
    "        if final_mask.shape[0] > 0: mask_centroid_y_norm = mask_centroid_y / final_mask.shape[0]\n",
    "        hu_moments_calc = cv2.HuMoments(M)\n",
    "        if hu_moments_calc is not None: hu_moments = hu_moments_calc.flatten()\n",
    "\n",
    "    # Features from the color mask (after morphology)\n",
    "    color_mask_pixel_count = float(np.sum(color_mask_morphed > 0))\n",
    "    color_mask_area_ratio = color_mask_pixel_count / (color_mask_morphed.shape[0] * color_mask_morphed.shape[1]) if (color_mask_morphed.shape[0] * color_mask_morphed.shape[1]) > 0 else 0.0\n",
    "\n",
    "    current_features = {\n",
    "        \"cx\": cx, \"num_detected_lines\": num_detected_lines,\n",
    "        \"avg_line_length\": avg_line_length, \"total_line_length\": total_line_length,\n",
    "        \"std_line_length\": std_line_length, \"avg_line_angle_deg\": avg_line_angle_deg,\n",
    "        \"std_line_angle_deg\": std_line_angle_deg, \"line_cx_mean\": line_cx_mean,\n",
    "        \"line_cx_std\": line_cx_std, \"line_cy_mean\": line_cy_mean,\n",
    "        \"longest_line_length\": longest_line_length, \"longest_line_angle_deg\": longest_line_angle_deg,\n",
    "        \"mask_pixel_count\": mask_pixel_count, \"mask_area_ratio\": mask_area_ratio,\n",
    "        \"mask_centroid_x_norm\": mask_centroid_x_norm, \"mask_centroid_y_norm\": mask_centroid_y_norm,\n",
    "        \"mask_hu_moment_1\": hu_moments[0] if len(hu_moments) > 0 else 0.0,\n",
    "        \"mask_hu_moment_2\": hu_moments[1] if len(hu_moments) > 1 else 0.0,\n",
    "        \"mask_hu_moment_3\": hu_moments[2] if len(hu_moments) > 2 else 0.0,\n",
    "        \"mask_hu_moment_4\": hu_moments[3] if len(hu_moments) > 3 else 0.0,\n",
    "        \"mask_hu_moment_5\": hu_moments[4] if len(hu_moments) > 4 else 0.0,\n",
    "        \"mask_hu_moment_6\": hu_moments[5] if len(hu_moments) > 5 else 0.0,\n",
    "        \"mask_hu_moment_7\": hu_moments[6] if len(hu_moments) > 6 else 0.0,\n",
    "        \"color_mask_pixel_count\": color_mask_pixel_count,\n",
    "        \"color_mask_area_ratio\": color_mask_area_ratio,\n",
    "        \"is_line_detected_binary\": is_line_detected_binary\n",
    "    }\n",
    "\n",
    "# Ensure all features are present in the DataFrame, matching the order from training\n",
    "input_features_df = pd.DataFrame([current_features])\n",
    "try:\n",
    "    # Ensure all expected columns are present, fill with NaN if missing, then reorder\n",
    "    # This handles cases where some features might not be calculated if no lines are found\n",
    "    # and ensures the DataFrame structure matches what the scaler expects.\n",
    "    # However, the current_features dictionary should already have all keys with default values.\n",
    "    input_features_df_ordered = input_features_df.reindex(columns=feature_columns_order, fill_value=0.0)\n",
    "    # input_features_df_ordered = input_features_df[feature_columns_order] # Original line, assuming all features always present\n",
    "except KeyError as e:\n",
    "    print(f\"Error: A feature expected by the scaler was not found after attempting to reindex: {e}.\")\n",
    "    print(f\"Extracted features keys: {list(current_features.keys())}\")\n",
    "    print(f\"Scaler expected features: {feature_columns_order}\")\n",
    "    print(\"Please ensure all features in 'feature_columns_order' are being calculated and added to 'current_features'.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error reordering feature columns: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 4. Scale the Input Features ---\n",
    "try:\n",
    "    input_features_scaled = loaded_feature_scaler.transform(input_features_df_ordered)\n",
    "except ValueError as e:\n",
    "    print(f\"Error during feature scaling: {e}. Provided shape: {input_features_df_ordered.shape}, Columns: {input_features_df_ordered.columns.tolist()}\")\n",
    "    if hasattr(loaded_feature_scaler, 'n_features_in_'): print(f\"Scaler expected features: {loaded_feature_scaler.n_features_in_}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error during feature scaling: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 5. Make the Prediction (Output is in Scaled Target Space) ---\n",
    "scaled_prediction_value = None # Initialize\n",
    "original_scale_prediction = None # Initialize\n",
    "\n",
    "# Check if line was detected by OpenCV and set scaled_prediction_value to 0.0 if not\n",
    "if current_features.get(\"is_line_detected_binary\", 1.0) == 0.0: # Default to 1.0 (line detected) if key is missing for safety\n",
    "    print(\"   Info: No line detected by OpenCV. Setting scaled prediction value to 0.0.\")\n",
    "    scaled_prediction_value = 0.0\n",
    "    original_scale_prediction = 0.0 # Also set original scale prediction to 0 for consistency\n",
    "else:\n",
    "    try:\n",
    "        scaled_prediction_value = loaded_model.predict(input_features_scaled)[0]\n",
    "        # Only inverse transform if a line was detected and a prediction was made by the model\n",
    "        try:\n",
    "            original_scale_prediction = loaded_target_scaler.inverse_transform(np.array([[scaled_prediction_value]]))[0][0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error during inverse transformation of prediction: {e}\")\n",
    "            print(f\"   Scaled Prediction Value (inverse transform failed): {scaled_prediction_value:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model prediction: {e}\")\n",
    "        # scaled_prediction_value remains None, and original_scale_prediction remains None\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "runtime_ms = (end_time - start_time) * 1000 # Calculate runtime after all processing\n",
    "print(f\"\\nPrediction runtime (feature extraction, scaling, prediction, inv. transform, override): {runtime_ms:.2f} ms\")\n",
    "\n",
    "# --- 7. Output the Final Prediction ---\n",
    "print(f\"\\nPrediction for '{os.path.basename(image_path)}':\")\n",
    "print(f\"   Feature 'is_line_detected_binary': {current_features.get('is_line_detected_binary', 'N/A')}\") # Show the detection status\n",
    "if scaled_prediction_value is not None:\n",
    "    print(f\"   Scaled Prediction Value (cx, from model/override): {scaled_prediction_value:.4f}\")\n",
    "else:\n",
    "    print(\"   Scaled Prediction Value: Not available (error during prediction or line not detected logic).\")\n",
    "\n",
    "if original_scale_prediction is not None:\n",
    "    print(f\"   Predicted Value (cx, original scale after inverse transform/override): {original_scale_prediction:.4f}\")\n",
    "else:\n",
    "    print(\"   Original Scale Prediction: Not available (error during inverse transformation or line not detected logic).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
