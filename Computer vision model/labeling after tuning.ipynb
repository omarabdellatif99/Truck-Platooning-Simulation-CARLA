{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2908100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1291 images from C:/Users/BCI-Lab/Downloads/teamA_dataset/_out_dataset/good_data...\n",
      "❌ Cannot read 00424873.png. Skipping.\n",
      "❌ Cannot read 00424913.png. Skipping.\n",
      "❌ Cannot read 00424954.png. Skipping.\n",
      "❌ Cannot read 00424995.png. Skipping.\n",
      "❌ Cannot read 00425279.png. Skipping.\n",
      "❌ Cannot read 00425317.png. Skipping.\n",
      "❌ Cannot read 00425357.png. Skipping.\n",
      "❌ Cannot read 00425396.png. Skipping.\n",
      "❌ Cannot read 00425435.png. Skipping.\n",
      "❌ Cannot read 00426295.png. Skipping.\n",
      "❌ Cannot read 00426826.png. Skipping.\n",
      "❌ Cannot read 00426867.png. Skipping.\n",
      "❌ Cannot read 00426908.png. Skipping.\n",
      "❌ Cannot read 00426949.png. Skipping.\n",
      "❌ Cannot read 00427113.png. Skipping.\n",
      "❌ Cannot read 00427317.png. Skipping.\n",
      "❌ Cannot read 00428804.png. Skipping.\n",
      "❌ Cannot read 00428845.png. Skipping.\n",
      "❌ Cannot read 00428923.png. Skipping.\n",
      "❌ Cannot read 00428996.png. Skipping.\n",
      "❌ Cannot read 00429032.png. Skipping.\n",
      "❌ Cannot read 00429068.png. Skipping.\n",
      "❌ Cannot read 00429106.png. Skipping.\n",
      "❌ Cannot read 00429144.png. Skipping.\n",
      "❌ Cannot read 00429183.png. Skipping.\n",
      "❌ Cannot read 00429224.png. Skipping.\n",
      "❌ Cannot read 00435827.png. Skipping.\n",
      "❌ Cannot read 00435900.png. Skipping.\n",
      "❌ Cannot read 00435938.png. Skipping.\n",
      "❌ Cannot read 00435976.png. Skipping.\n",
      "❌ Cannot read 00436012.png. Skipping.\n",
      "❌ Cannot read 00441416.png. Skipping.\n",
      "❌ Cannot read 00441866.png. Skipping.\n",
      "❌ Cannot read 00441907.png. Skipping.\n",
      "❌ Cannot read 00441988.png. Skipping.\n",
      "❌ Cannot read 00455055.png. Skipping.\n",
      "❌ Cannot read 00455096.png. Skipping.\n",
      "❌ Cannot read 00455137.png. Skipping.\n",
      "❌ Cannot read 00455178.png. Skipping.\n",
      "❌ Cannot read 00455219.png. Skipping.\n",
      "❌ Cannot read 00455454.png. Skipping.\n",
      "❌ Cannot read 00455576.png. Skipping.\n",
      "❌ Cannot read 00455656.png. Skipping.\n",
      "❌ Cannot read 00455697.png. Skipping.\n",
      "❌ Cannot read 00455737.png. Skipping.\n",
      "❌ Cannot read 00455776.png. Skipping.\n",
      "❌ Cannot read 00455816.png. Skipping.\n",
      "❌ Cannot read 00455897.png. Skipping.\n",
      "❌ Cannot read 00455938.png. Skipping.\n",
      "❌ Cannot read 00456344.png. Skipping.\n",
      "❌ Cannot read 00456382.png. Skipping.\n",
      "❌ Cannot read 00456420.png. Skipping.\n",
      "❌ Cannot read 00456497.png. Skipping.\n",
      "❌ Cannot read 00456536.png. Skipping.\n",
      "❌ Cannot read 00456575.png. Skipping.\n",
      "❌ Cannot read 00456613.png. Skipping.\n",
      "❌ Cannot read 00456694.png. Skipping.\n",
      "❌ Cannot read 00456734.png. Skipping.\n",
      "❌ Cannot read 00456774.png. Skipping.\n",
      "❌ Cannot read 00456814.png. Skipping.\n",
      "❌ Cannot read 00456854.png. Skipping.\n",
      "❌ Cannot read 00456894.png. Skipping.\n",
      "❌ Cannot read 00456935.png. Skipping.\n",
      "❌ Cannot read 00456976.png. Skipping.\n",
      "❌ Cannot read 00461967.png. Skipping.\n",
      "❌ Cannot read 00462007.png. Skipping.\n",
      "❌ Cannot read 00462123.png. Skipping.\n",
      "❌ Cannot read 00462203.png. Skipping.\n",
      "❌ Cannot read 00462243.png. Skipping.\n",
      "❌ Cannot read 00462284.png. Skipping.\n",
      "❌ Cannot read 00462324.png. Skipping.\n",
      "❌ Cannot read 00462364.png. Skipping.\n",
      "❌ Cannot read 00462444.png. Skipping.\n",
      "❌ Cannot read 00462770.png. Skipping.\n",
      "❌ Cannot read 00462811.png. Skipping.\n",
      "❌ Cannot read 00463484.png. Skipping.\n",
      "❌ Cannot read 00463522.png. Skipping.\n",
      "❌ Cannot read 00463642.png. Skipping.\n",
      "❌ Cannot read 00463683.png. Skipping.\n",
      "❌ Cannot read 00463878.png. Skipping.\n",
      "❌ Cannot read 00465699.png. Skipping.\n",
      "❌ Cannot read 00466820.png. Skipping.\n",
      "❌ Cannot read 00466859.png. Skipping.\n",
      "❌ Cannot read 00466938.png. Skipping.\n",
      "❌ Cannot read 00466979.png. Skipping.\n",
      "❌ Cannot read 00467020.png. Skipping.\n",
      "❌ Cannot read 00467060.png. Skipping.\n",
      "❌ Cannot read 00467182.png. Skipping.\n",
      "❌ Cannot read 00467456.png. Skipping.\n",
      "❌ Cannot read 00467494.png. Skipping.\n",
      "❌ Cannot read 00467534.png. Skipping.\n",
      "❌ Cannot read 00467575.png. Skipping.\n",
      "❌ Cannot read 00467616.png. Skipping.\n",
      "❌ Cannot read 00467697.png. Skipping.\n",
      "❌ Cannot read 00467738.png. Skipping.\n",
      "❌ Cannot read 00467778.png. Skipping.\n",
      "❌ Cannot read 00467818.png. Skipping.\n",
      "❌ Cannot read 00467859.png. Skipping.\n",
      "❌ Cannot read 00467900.png. Skipping.\n",
      "❌ Cannot read 00467941.png. Skipping.\n",
      "❌ Cannot read 00467982.png. Skipping.\n",
      "❌ Cannot read 00468022.png. Skipping.\n",
      "❌ Cannot read 00468062.png. Skipping.\n",
      "❌ Cannot read 00468102.png. Skipping.\n",
      "❌ Cannot read 00468222.png. Skipping.\n",
      "❌ Cannot read 00468303.png. Skipping.\n",
      "❌ Cannot read 00468384.png. Skipping.\n",
      "❌ Cannot read 00468425.png. Skipping.\n",
      "❌ Cannot read 00468465.png. Skipping.\n",
      "❌ Cannot read 00468586.png. Skipping.\n",
      "❌ Cannot read 00468666.png. Skipping.\n",
      "❌ Cannot read 00468706.png. Skipping.\n",
      "❌ Cannot read 00468745.png. Skipping.\n",
      "❌ Cannot read 00468783.png. Skipping.\n",
      "❌ Cannot read 00468821.png. Skipping.\n",
      "❌ Cannot read 00468859.png. Skipping.\n",
      "❌ Cannot read 00468899.png. Skipping.\n",
      "❌ Cannot read 00468981.png. Skipping.\n",
      "❌ Cannot read 00469022.png. Skipping.\n",
      "❌ Cannot read 00469063.png. Skipping.\n",
      "❌ Cannot read 00469104.png. Skipping.\n",
      "❌ Cannot read 00469145.png. Skipping.\n",
      "❌ Cannot read 00469185.png. Skipping.\n",
      "❌ Cannot read 00469226.png. Skipping.\n",
      "❌ Cannot read 00469267.png. Skipping.\n",
      "❌ Cannot read 00469308.png. Skipping.\n",
      "❌ Cannot read 00469349.png. Skipping.\n",
      "❌ Cannot read 00469389.png. Skipping.\n",
      "❌ Cannot read 00469509.png. Skipping.\n",
      "❌ Cannot read 00469912.png. Skipping.\n",
      "❌ Cannot read 00469952.png. Skipping.\n",
      "❌ Cannot read 00470029.png. Skipping.\n",
      "❌ Cannot read 00470068.png. Skipping.\n",
      "❌ Cannot read 00470106.png. Skipping.\n",
      "❌ Cannot read 00470182.png. Skipping.\n",
      "❌ Cannot read 00470220.png. Skipping.\n",
      "❌ Cannot read 00470258.png. Skipping.\n",
      "❌ Cannot read 00470296.png. Skipping.\n",
      "❌ Cannot read 00470334.png. Skipping.\n",
      "❌ Cannot read 00470374.png. Skipping.\n",
      "\n",
      "✅ Feature extraction complete! Data saved to 'line_detection_features.csv'\n",
      "Total images processed: 1151\n",
      "Label Distribution:\n",
      "line_label\n",
      " 0    596\n",
      " 1    221\n",
      "-1    220\n",
      " 2    114\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- USER-DEFINED OPTIMIZED PARAMETERS ---\n",
    "# REPLACE THESE VALUES with the \"perfect variables\" you found during tuning!\n",
    "OPTIMIZED_PARAMS = {\n",
    "    \"lower_L\": 137,\n",
    "    \"upper_L\": 255,\n",
    "    \"lower_A\": 134,\n",
    "    \"upper_A\": 161,\n",
    "    \"lower_B\": 138,\n",
    "    \"upper_B\": 165,\n",
    "    \"color_morph_kernel_size\": 3,\n",
    "    \"edge_morph_kernel_size\": 7,\n",
    "    \"canny_thresh1\": 18,\n",
    "    \"canny_thresh2\": 66,\n",
    "    \"hough_threshold\": 57,       # Min votes for a line\n",
    "    \"hough_min_length\": 18,      # Min line length\n",
    "    \"hough_max_gap\": 17,         # Max gap to connect segments\n",
    "    \"crop_percent\": 55,\n",
    "    \"line_center_tolerance_percent\": 10 # Percentage of image width for \"center\" tolerance\n",
    "}\n",
    "\n",
    "# --- Configuration ---\n",
    "image_folder = \"C:/Users/BCI-Lab/Downloads/teamA_dataset/_out_dataset/good_data\"\n",
    "output_csv_path = \"line_detection_features.csv\" # Output CSV file name\n",
    "\n",
    "# List to store features and labels for each image\n",
    "all_image_data = []\n",
    "\n",
    "# --- Main Processing Loop ---\n",
    "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\"))]\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(f\"No images found in {image_folder}. Please check the path or file extensions.\")\n",
    "else:\n",
    "    print(f\"Processing {len(image_files)} images from {image_folder}...\")\n",
    "\n",
    "for filename in image_files:\n",
    "    filepath = os.path.join(image_folder, filename)\n",
    "    image = cv2.imread(filepath)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"❌ Cannot read {filename}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    current_features = {\"filename\": filename}\n",
    "    \n",
    "    # --- 1. Crop from top ---\n",
    "    crop_y = int(image.shape[0] * OPTIMIZED_PARAMS[\"crop_percent\"] / 100)\n",
    "    if crop_y >= image.shape[0]:\n",
    "        crop_y = image.shape[0] - 1\n",
    "    cropped_image = image[crop_y:, :].copy()\n",
    "    \n",
    "    # Check if cropped image is valid before proceeding\n",
    "    if cropped_image.shape[0] == 0 or cropped_image.shape[1] == 0:\n",
    "        print(f\"Warning: Cropped image for {filename} is empty. Skipping feature extraction.\")\n",
    "        # Fill with default/zero features for this image\n",
    "        current_features.update({\n",
    "            \"line_label\": 2, # No line detected due to empty crop\n",
    "            \"cx\": -1,\n",
    "            \"num_detected_lines\": 0,\n",
    "            \"avg_line_length\": 0,\n",
    "            \"total_line_length\": 0,\n",
    "            \"std_line_length\": 0,\n",
    "            \"avg_line_angle_deg\": 0,\n",
    "            \"std_line_angle_deg\": 0,\n",
    "            \"line_cx_mean\": -1,\n",
    "            \"line_cx_std\": 0,\n",
    "            \"line_cy_mean\": -1,\n",
    "            \"longest_line_length\": 0,\n",
    "            \"longest_line_angle_deg\": 0,\n",
    "            \"mask_pixel_count\": 0,\n",
    "            \"mask_area_ratio\": 0,\n",
    "            \"mask_centroid_x_norm\": 0.5, # Assume center if no mask\n",
    "            \"mask_centroid_y_norm\": 0.5,\n",
    "            \"mask_hu_moment_1\": 0, \"mask_hu_moment_2\": 0, \"mask_hu_moment_3\": 0,\n",
    "            \"mask_hu_moment_4\": 0, \"mask_hu_moment_5\": 0, \"mask_hu_moment_6\": 0, \"mask_hu_moment_7\": 0,\n",
    "            \"color_mask_pixel_count\": 0,\n",
    "            \"color_mask_area_ratio\": 0,\n",
    "            \"is_line_detected_binary\": 0\n",
    "        })\n",
    "        all_image_data.append(current_features)\n",
    "        continue\n",
    "\n",
    "    # --- 2. Color Masking (L*a*b*) ---\n",
    "    lab_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_cropped)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    l_eq = clahe.apply(l_channel)\n",
    "    lab_eq = cv2.merge([l_eq, a_channel, b_channel])\n",
    "    blurred_lab_eq = cv2.medianBlur(lab_eq, 5)\n",
    "\n",
    "    lower_orange_lab = np.array([OPTIMIZED_PARAMS[\"lower_L\"], OPTIMIZED_PARAMS[\"lower_A\"], OPTIMIZED_PARAMS[\"lower_B\"]])\n",
    "    upper_orange_lab = np.array([OPTIMIZED_PARAMS[\"upper_L\"], OPTIMIZED_PARAMS[\"upper_A\"], OPTIMIZED_PARAMS[\"upper_B\"]])\n",
    "    color_mask = cv2.inRange(blurred_lab_eq, lower_orange_lab, upper_orange_lab)\n",
    "\n",
    "    # --- 3. Morphological Operations on Color Mask ---\n",
    "    color_morph_kernel = np.ones((OPTIMIZED_PARAMS[\"color_morph_kernel_size\"], OPTIMIZED_PARAMS[\"color_morph_kernel_size\"]), np.uint8)\n",
    "    color_mask_morphed = cv2.morphologyEx(color_mask, cv2.MORPH_OPEN, color_morph_kernel, iterations=1)\n",
    "    color_mask_morphed = cv2.dilate(color_mask_morphed, color_morph_kernel, iterations=1) \n",
    "    color_mask_morphed = cv2.morphologyEx(color_mask_morphed, cv2.MORPH_CLOSE, color_morph_kernel, iterations=1)\n",
    "    \n",
    "    # --- 4. Edge Detection (Canny) ---\n",
    "    gray_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_gray = cv2.GaussianBlur(gray_cropped, (5, 5), 0)\n",
    "    edge_mask = cv2.Canny(blurred_gray, OPTIMIZED_PARAMS[\"canny_thresh1\"], OPTIMIZED_PARAMS[\"canny_thresh2\"])\n",
    "\n",
    "    # Morphological Operations on Edge Mask to connect broken edges\n",
    "    edge_morph_kernel = np.ones((OPTIMIZED_PARAMS[\"edge_morph_kernel_size\"], OPTIMIZED_PARAMS[\"edge_morph_kernel_size\"]), np.uint8)\n",
    "    edge_mask_morphed = cv2.morphologyEx(edge_mask, cv2.MORPH_CLOSE, edge_morph_kernel, iterations=1)\n",
    "\n",
    "    # --- 5. Combine Color Mask and Morphed Edge Mask ---\n",
    "    final_mask = cv2.bitwise_and(color_mask_morphed, edge_mask_morphed)\n",
    "\n",
    "    # --- 6. Line Detection with Hough Transform ---\n",
    "    lines = cv2.HoughLinesP(final_mask, 1, np.pi / 180, \n",
    "                            OPTIMIZED_PARAMS[\"hough_threshold\"], \n",
    "                            minLineLength=OPTIMIZED_PARAMS[\"hough_min_length\"], \n",
    "                            maxLineGap=OPTIMIZED_PARAMS[\"hough_max_gap\"])\n",
    "    \n",
    "    # --- Feature Extraction and Labeling ---\n",
    "    line_label = 2  # Default: No Line Detected\n",
    "    cx = -1 # Default centroid x-coordinate\n",
    "    \n",
    "    img_width = image.shape[1]\n",
    "    center_x_img = img_width // 2\n",
    "    tolerance = img_width * OPTIMIZED_PARAMS[\"line_center_tolerance_percent\"] / 100\n",
    "\n",
    "    # Initialize line features\n",
    "    num_detected_lines = 0\n",
    "    avg_line_length = 0\n",
    "    total_line_length = 0\n",
    "    std_line_length = 0\n",
    "    avg_line_angle_deg = 0\n",
    "    std_line_angle_deg = 0\n",
    "    line_cx_mean = -1\n",
    "    line_cx_std = 0\n",
    "    line_cy_mean = -1\n",
    "    longest_line_length = 0\n",
    "    longest_line_angle_deg = 0\n",
    "    is_line_detected_binary = 0\n",
    "\n",
    "    if lines is not None:\n",
    "        is_line_detected_binary = 1\n",
    "        num_detected_lines = len(lines)\n",
    "        \n",
    "        all_line_midpoints_x = []\n",
    "        all_line_midpoints_y = []\n",
    "        line_lengths = []\n",
    "        line_angles_rad = []\n",
    "        \n",
    "        # Track longest line for a specific feature\n",
    "        max_length_found = 0\n",
    "        angle_of_longest_line = 0\n",
    "\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            \n",
    "            # Line length\n",
    "            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "            line_lengths.append(length)\n",
    "\n",
    "            if length > max_length_found:\n",
    "                max_length_found = length\n",
    "                angle_of_longest_line = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi # Angle in degrees\n",
    "\n",
    "            # Line angle (in radians, then convert to degrees for feature)\n",
    "            angle_rad = np.arctan2(y2 - y1, x2 - x1)\n",
    "            line_angles_rad.append(angle_rad)\n",
    "\n",
    "            # Midpoints\n",
    "            mid_x = (x1 + x2) // 2\n",
    "            mid_y = (y1 + y2) // 2 # Y is relative to cropped_image, not original\n",
    "            all_line_midpoints_x.append(mid_x)\n",
    "            all_line_midpoints_y.append(mid_y)\n",
    "        \n",
    "        # Calculate aggregated line features\n",
    "        if line_lengths:\n",
    "            avg_line_length = np.mean(line_lengths)\n",
    "            total_line_length = np.sum(line_lengths)\n",
    "            std_line_length = np.std(line_lengths) if len(line_lengths) > 1 else 0\n",
    "            longest_line_length = max_length_found\n",
    "            longest_line_angle_deg = angle_of_longest_line\n",
    "        \n",
    "        if line_angles_rad:\n",
    "            # Angles from atan2 range from -pi to pi. Normalize to 0 to 180 for line orientation\n",
    "            normalized_angles_deg = [angle % 180 for angle in np.degrees(line_angles_rad)]\n",
    "            avg_line_angle_deg = np.mean(normalized_angles_deg)\n",
    "            std_line_angle_deg = np.std(normalized_angles_deg) if len(normalized_angles_deg) > 1 else 0\n",
    "\n",
    "        if all_line_midpoints_x:\n",
    "            cx = int(np.mean(all_line_midpoints_x))\n",
    "            line_cx_mean = cx\n",
    "            line_cx_std = np.std(all_line_midpoints_x) if len(all_line_midpoints_x) > 1 else 0\n",
    "            line_cy_mean = int(np.mean(all_line_midpoints_y)) # Mean Y relative to cropped, used for feature\n",
    "\n",
    "            if abs(cx - cropped_image.shape[1] // 2) < tolerance: # Use cropped image center\n",
    "                line_label = 0  # Line in Center\n",
    "            elif cx < cropped_image.shape[1] // 2 - tolerance:\n",
    "                line_label = -1 # Line on Left\n",
    "            else:\n",
    "                line_label = 1  # Line on Right\n",
    "        else: # No lines found, but `lines` was not None (e.g. empty array)\n",
    "            line_label = 2\n",
    "    else: # No lines found (lines is None)\n",
    "        line_label = 2\n",
    "\n",
    "    # --- Features from Final Mask ---\n",
    "    mask_pixel_count = np.sum(final_mask > 0)\n",
    "    mask_area_ratio = mask_pixel_count / (final_mask.shape[0] * final_mask.shape[1]) if (final_mask.shape[0] * final_mask.shape[1]) > 0 else 0\n",
    "\n",
    "    # Calculate moments for centroid and Hu Moments (shape descriptors)\n",
    "    M = cv2.moments(final_mask)\n",
    "    if M[\"m00\"] != 0:\n",
    "        mask_centroid_x = M[\"m10\"] / M[\"m00\"]\n",
    "        mask_centroid_y = M[\"m01\"] / M[\"m00\"]\n",
    "        mask_centroid_x_norm = mask_centroid_x / final_mask.shape[1] # Normalized to [0,1]\n",
    "        mask_centroid_y_norm = mask_centroid_y / final_mask.shape[0] # Normalized to [0,1]\n",
    "        hu_moments = cv2.HuMoments(M).flatten()\n",
    "        current_features.update({\n",
    "            \"mask_centroid_x_norm\": mask_centroid_x_norm,\n",
    "            \"mask_centroid_y_norm\": mask_centroid_y_norm,\n",
    "            \"mask_hu_moment_1\": hu_moments[0], \"mask_hu_moment_2\": hu_moments[1], \"mask_hu_moment_3\": hu_moments[2],\n",
    "            \"mask_hu_moment_4\": hu_moments[3], \"mask_hu_moment_5\": hu_moments[4], \"mask_hu_moment_6\": hu_moments[5], \"mask_hu_moment_7\": hu_moments[6],\n",
    "        })\n",
    "    else:\n",
    "        current_features.update({\n",
    "            \"mask_centroid_x_norm\": 0.5, # Default to center if no mask\n",
    "            \"mask_centroid_y_norm\": 0.5,\n",
    "            \"mask_hu_moment_1\": 0, \"mask_hu_moment_2\": 0, \"mask_hu_moment_3\": 0,\n",
    "            \"mask_hu_moment_4\": 0, \"mask_hu_moment_5\": 0, \"mask_hu_moment_6\": 0, \"mask_hu_moment_7\": 0,\n",
    "        })\n",
    "    \n",
    "    # --- Features from Morphed Color Mask ---\n",
    "    color_mask_pixel_count = np.sum(color_mask_morphed > 0)\n",
    "    color_mask_area_ratio = color_mask_pixel_count / (color_mask_morphed.shape[0] * color_mask_morphed.shape[1]) if (color_mask_morphed.shape[0] * color_mask_morphed.shape[1]) > 0 else 0\n",
    "\n",
    "    # --- Store all features for this image ---\n",
    "    current_features.update({\n",
    "        \"line_label\": line_label,\n",
    "        \"cx\": cx, # This is the x-coordinate used for labeling, relative to cropped image\n",
    "        \"num_detected_lines\": num_detected_lines,\n",
    "        \"avg_line_length\": avg_line_length,\n",
    "        \"total_line_length\": total_line_length,\n",
    "        \"std_line_length\": std_line_length,\n",
    "        \"avg_line_angle_deg\": avg_line_angle_deg,\n",
    "        \"std_line_angle_deg\": std_line_angle_deg,\n",
    "        \"line_cx_mean\": line_cx_mean, # Mean of x-coords of line midpoints (relative to cropped image)\n",
    "        \"line_cx_std\": line_cx_std,\n",
    "        \"line_cy_mean\": line_cy_mean, # Mean of y-coords of line midpoints (relative to cropped image)\n",
    "        \"longest_line_length\": longest_line_length,\n",
    "        \"longest_line_angle_deg\": longest_line_angle_deg,\n",
    "        \"mask_pixel_count\": mask_pixel_count,\n",
    "        \"mask_area_ratio\": mask_area_ratio,\n",
    "        \"color_mask_pixel_count\": color_mask_pixel_count,\n",
    "        \"color_mask_area_ratio\": color_mask_area_ratio,\n",
    "        \"is_line_detected_binary\": is_line_detected_binary,\n",
    "        # Potentially add color features from original image if needed, e.g., mean L, A, B in cropped region\n",
    "    })\n",
    "    all_image_data.append(current_features)\n",
    "\n",
    "# --- Save Features to CSV ---\n",
    "if all_image_data:\n",
    "    df = pd.DataFrame(all_image_data)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"\\n✅ Feature extraction complete! Data saved to '{output_csv_path}'\")\n",
    "    print(f\"Total images processed: {len(df)}\")\n",
    "    print(f\"Label Distribution:\\n{df['line_label'].value_counts()}\")\n",
    "else:\n",
    "    print(\"\\nNo images were processed, so no CSV file was generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features from 1151 images.\n",
      "Feature matrix shape: (1151, 2)\n",
      "Labels vector shape: (1151,)\n",
      "Features and labels saved to C:/Users/BCI-Lab/Downloads/teamA_dataset/_out_dataset/good_data\\features_labels.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f6c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a02ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1151, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        10\n",
      "           0       1.00      1.00      1.00       142\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       1.00      1.00      1.00        61\n",
      "\n",
      "    accuracy                           1.00       231\n",
      "   macro avg       1.00      1.00      1.00       231\n",
      "weighted avg       1.00      1.00      1.00       231\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 10   0   0   0]\n",
      " [  0 142   0   0]\n",
      " [  0   0  18   0]\n",
      " [  0   0   0  61]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1e026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      " 0    567\n",
      " 2    241\n",
      " 1     73\n",
      "-1     39\n",
      "Name: count, dtype: int64\n",
      "label\n",
      " 0    142\n",
      " 2     61\n",
      " 1     18\n",
      "-1     10\n",
      "Name: count, dtype: int64\n",
      "Training Accuracy: 1.0000\n",
      "Validation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
